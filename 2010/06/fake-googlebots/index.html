<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/2010/styles.742409eb857ab2ccca34.css" data-identity="gatsby-global-css">li{margin-right:1rem}h1,li{display:inline-block}h1{font-style:normal;margin-top:0}header{margin-bottom:1.5rem}header ul{float:right;list-style:none}#wrapper{margin:3em auto;max-width:700px;padding:10px}.blogPostDate{color:#333;font-size:8pt;margin-bottom:9px;padding-top:4px}</style><meta name="generator" content="Gatsby 4.4.0"/><title data-react-helmet="true">Fake Googlebots</title><link data-react-helmet="true" rel="canonical" href="https://www.docunext.com/2010/06/fake-googlebots/"/><link as="script" rel="preload" href="/2010/webpack-runtime-64714893fad3d6616b95.js"/><link as="script" rel="preload" href="/2010/framework-3b46cba0dfed09aeeb64.js"/><link as="script" rel="preload" href="/2010/app-00c377d84359908eff43.js"/><link as="script" rel="preload" href="/2010/commons-07a951b24cae11aa6a48.js"/><link as="script" rel="preload" href="/2010/component---src-templates-blog-post-js-4450b810c5cd340eaea8.js"/><link as="fetch" rel="preload" href="/2010/page-data/2010/06/fake-googlebots/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/2010/page-data/sq/d/4224293195.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/2010/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div id="wrapper"><header><ul><li><a href="/about/">About</a></li></ul><a href="/"><h1>Docunext</h1></a></header><hr/><div><h2>Fake Googlebots</h2><div class="blogPostDate">June 1st, 2010</div><div><p>There are some HTTP clients accessing my web servers with strange request patterns. They include a header stating that they are a Googlebot, but its clear that they are <strong>fake googlebots</strong>.</p>
<h4><strong>Detection of Fake Googlebots</strong></h4>
<p>I noticed some HTTP clients spoofing Google's search crawler user-agent, aka "Googlebot", like these:</p>
<pre class="sh_sh">
404 www.neosensorz.com "GET /wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.014
404 www.neosensorz.com "GET /old/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.007
404 www.neosensorz.com "GET /cms/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.007
404 www.neosensorz.com "GET /blog/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.005
404 www.neosensorz.com "GET /blog_old/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /blog-old/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.007
404 www.neosensorz.com "GET /blog/wp/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /wp/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /WP/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.004
404 www.neosensorz.com "GET /backup/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /blog/backup/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /wordpress/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.006
404 www.neosensorz.com "GET /Wordpress/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.005
404 www.neosensorz.com "GET /wordpress2/wp-login.php HTTP/1.1" "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" 67.19.102.242 0.008
</pre>
<p>I started to think about ways to automatically block them. I didn't figure that Google would provide a list of CIDR blocks, and based upon what I've read, it would appear that I was right, they don't. I read on their blog that they suggest using DNS to do a reverse lookup and see if it contains their domain name, like this:</p>
<pre class="sh_sh">
$ dig -x 66.249.71.155
; &lt;&lt;>> DiG 9.6.1-P1 &lt;&lt;>> -x 66.249.71.155
;; global options: +cmd
;; Got answer:
;; ->>HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63653
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0
;; QUESTION SECTION:
;155.71.249.66.in-addr.arpa.	IN	PTR
;; ANSWER SECTION:
155.71.249.66.in-addr.arpa. 86400 IN	PTR	crawl-66-249-71-155.googlebot.com.
;; Query time: 157 msec
;; SERVER: 192.168.1.1#53(192.168.1.1)
;; WHEN: Tue Jun  1 02:49:14 2010
;; MSG SIZE  rcvd: 91
</pre>
<p>Since I use NGINX as the front-most web server, I could manually set non-Google ip addresses in a <strong>"map"</strong> block and check them when the user-agent contains the Googlebot string, something like this:</p>
<pre class="sh_c">
map  $remote_addr  $nogip  {
default 0;
67.19.102.242 1;
}
if ($http_user_agent ~ Googlebot) {
  set $noacc $nogip;
}
if ($http_user_agent !~ Googlebot) {
  set $noacc 0;
}
if ($noacc = 1) {
  return 503;
}
</pre>
<p>I doubt I'll set this up though, its too specific!</p></div></div><div><span>Yearly Indexes: </span><span><a href="/2003"><span>2003</span></a> </span><span><a href="/2004"><span>2004</span></a> </span><span><a href="/2006"><span>2006</span></a> </span><span><a href="/2007"><span>2007</span></a> </span><span><a href="/2008"><span>2008</span></a> </span><span><a href="/2009"><span>2009</span></a> </span><span><a href="/2010"><span>2010</span></a> </span><span><a href="/2011"><span>2011</span></a> </span><span><a href="/2012"><span>2012</span></a> </span><span><a href="/2013"><span>2013</span></a> </span><span><a href="/2015"><span>2015</span></a> </span><span><a href="/2019"><span>2019</span></a> </span><span><a href="/2020"><span>2020</span></a> </span><span><a href="/2022"><span>2022</span></a> </span></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/2010/06/fake-googlebots/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-4633e8f6cc7cf1607dae.js"],"app":["/app-00c377d84359908eff43.js"],"component---src-pages-index-js":["/component---src-pages-index-js-a8b57182e60688a12d91.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-4450b810c5cd340eaea8.js"],"component---src-templates-year-js":["/component---src-templates-year-js-0397176bed9177a29771.js"]};/*]]>*/</script><script src="/2010/polyfill-4633e8f6cc7cf1607dae.js" nomodule=""></script><script src="/2010/component---src-templates-blog-post-js-4450b810c5cd340eaea8.js" async=""></script><script src="/2010/commons-07a951b24cae11aa6a48.js" async=""></script><script src="/2010/app-00c377d84359908eff43.js" async=""></script><script src="/2010/framework-3b46cba0dfed09aeeb64.js" async=""></script><script src="/2010/webpack-runtime-64714893fad3d6616b95.js" async=""></script></body></html>